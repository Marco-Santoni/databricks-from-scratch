{"cells":[{"cell_type":"code","source":["# sostituisci con il tuo nome e cognome\nNOME_COGNOME = \"bill_gates\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"96689714-e50f-48a1-9965-81b97ea4a7c6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Dataset\n\nIn this exam, we'll consider the San Francisco Fire Department Calls dataset.\n\n```\n/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\n```\n\n## Part 1\n\nWrite a function named `prepare_dataframe()` that\n\n- reads the csv file\n- excludes the records with `CallType` that occurs less than `200` times in the entire dataset (it is fine to hardcode the values manually)\n- computes a new column `CallDayOfWeek` that computes the day of the week (1 Sunday, 7 Saturday) based on the column `CallDate`\n- computes a new column `DeltaPriority` that computes the difference between `FinalPriority` and `OriginalPriority` (eg `DeltaPriority=2` when `FinalPriority=4` and `OriginalPriority=2`)\n- keeps only the following columns `CallNumber`, `CallType`, `Priority`, `CallDayOfWeek`, `DeltaPriority`, `Delay`\n- remove rows where any record is null (you can use `dropna`)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2f0cf33a-2791-47ae-8846-1dddd6f973c3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def prepare_dataframe() -> DataFrame:\n    # your code here\n    return df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a1df78f-3818-422b-8a6d-c8c0428e754b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650646>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mprepare_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'DataFrame' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650646>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mprepare_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Part 2\n\nWrite a function named `define_pipeline()` that\n\n- returns a `Pipeline` object\n- the object is initialized with stages that predict the `Delay` via a linear regression based on the following features: `CallType`, `Priority`, `CallDayOfWeek`, `DeltaPriority`. Two of these features can be considered as categorical, which are the 2?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fe7fff04-5ab8-4ded-a24c-a56d1d4a85e4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\ndef define_pipeline() -> Pipeline:\n    # your code here\n    return pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8835e074-6bca-4fb3-8ed2-73e79238cf18","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 3\n\nWrite a function named `fit_model(df, pipeline)` that\n- takes as input\n  - `df`, a `DataFrame` object that corresponds to the one that is returned by `prepare_dataframe()`\n  - `pipeline`, a `Pipeline` object that corresonds to the one that is returned by `define_pipeline()`\n- splits `df` in _train_ and _test_ dataset (80% and 20% respectively using a seed of `42`)\n- fits the `pipeline` on the _train_ dataset and runs prediction on the _test_ dataset\n- returns the `DataFrame` of the predictions made of only 2 columns: `DelayLabel`, `DelayPrediction`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8041edd-ac1b-4f36-b43a-afb2c69bacdd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def fit_model(df: DataFrame, pipeline: Pipeline) -> DataFrame:\n    # your code here\n    return predictions_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"135b436c-b583-4502-8f53-7c3149a5e8cd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650651>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mfit_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mPipeline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mpredictions_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'DataFrame' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650651>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mfit_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mPipeline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mpredictions_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Part 4\nWrite a function `evaluate_r2(predictions_df)` that\n- takes as input a `DataFrame` object that corresponds to the one that is returned by `fit_model()`, ie made of 2 columns `DelayLabel` and `DelayPrediction`\n- computes the R squared metric and returns the R2 value"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9322e8c-4dcf-4074-9a84-0e6d148ed508","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def evaluate_r2(predictions_df: DataFrame) -> float:\n    # your code here\n    return r2"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b0e3992a-e20a-4bda-848e-964c9f9ffb9c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650653>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mevaluate_r2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions_df\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mr2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'DataFrame' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-35732860650653>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mevaluate_r2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions_df\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0;31m# your code here\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mr2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'DataFrame' is not defined"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, FloatType\nfrom pyspark.sql.functions import to_date, dayofweek\n\ndef prepare_dataframe():\n    sf_fire_file = \"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\"\n\n    fire_schema = StructType(\n        [\n            StructField('CallNumber', IntegerType(), True),\n            StructField('UnitID', StringType(), True),\n            StructField('IncidentNumber', IntegerType(), True),\n            StructField('CallType', StringType(), True),                  \n            StructField('CallDate', StringType(), True),      \n            StructField('WatchDate', StringType(), True),\n            StructField('CallFinalDisposition', StringType(), True),\n            StructField('AvailableDtTm', StringType(), True),\n            StructField('Address', StringType(), True),       \n            StructField('City', StringType(), True),       \n            StructField('Zipcode', IntegerType(), True),       \n            StructField('Battalion', StringType(), True),                 \n            StructField('StationArea', StringType(), True),       \n            StructField('Box', StringType(), True),       \n            StructField('OriginalPriority', IntegerType(), True),       \n            StructField('Priority', IntegerType(), True),       \n            StructField('FinalPriority', IntegerType(), True),       \n            StructField('ALSUnit', BooleanType(), True),       \n            StructField('CallTypeGroup', StringType(), True),\n            StructField('NumAlarms', IntegerType(), True),\n            StructField('UnitType', StringType(), True),\n            StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n            StructField('FirePreventionDistrict', StringType(), True),\n            StructField('SupervisorDistrict', StringType(), True),\n            StructField('Neighborhood', StringType(), True),\n            StructField('Location', StringType(), True),\n            StructField('RowID', StringType(), True),\n            StructField('Delay', FloatType(), True)\n        ]\n    )\n\n    df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)\n    return df\\\n            .where(~df.CallType.isin(['Administrative', 'Train / Rail Fire', 'Lightning Strike (Investigation)']))\\\n            .withColumn(\n                \"CallDayOfWeek\",\n                dayofweek(to_date(df.CallDate, \"MM/dd/yyyy\"))\n            )\\\n            .withColumn('DeltaPriority', df.FinalPriority - df.OriginalPriority)\\\n            .select('CallNumber', 'CallType', 'Priority', 'CallDayOfWeek', 'DeltaPriority', 'Delay')\\\n            .dropna(how='any')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3daf93e4-3ce7-49de-ac0c-cd6ad45ec313","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(\"evaluate part 1\")\n\ndf = prepare_dataframe()\nexpected_columns = [\n    'CallDayOfWeek',\n    'CallNumber',\n    'CallType',\n    'Delay',\n    'DeltaPriority',\n    'Priority'\n]\ncols = df.columns\ncols.sort()\nprint(\"are columns equals?\")\nprint(cols == expected_columns)\n\nrows = 4085557\nprint(\"same number of rows?\")\nassertion = (rows == df.count())\nprint(assertion)\n\nprint(\"no rows to exclude\")\nassertion = df.where(df.CallType.isin(['Administrative', 'Train / Rail Fire', 'Lightning Strike (Investigation)'])).count() == 0\nprint(assertion)\n\nprint(\"check row 20110217\")\nrow = df.where(df.CallNumber == 20110217).collect()[0]\nprint(\"assert delay == 1\")\nprint( row['DeltaPriority'] == 1 )\nprint(\"assert week day == 6\")\nprint( row['CallDayOfWeek'] == 6)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"261a42ea-0bde-45c7-90ef-b353b3944860","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"evaluate part 1\nare columns equals?\nTrue\nsame number of rows?\nTrue\nno rows to exclude\nTrue\ncheck row 20110217\nassert delay == 1\nTrue\nassert week day == 6\nTrue\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["evaluate part 1\nare columns equals?\nTrue\nsame number of rows?\nTrue\nno rows to exclude\nTrue\ncheck row 20110217\nassert delay == 1\nTrue\nassert week day == 6\nTrue\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\n\ndef define_pipeline() -> Pipeline:\n    indexer = StringIndexer(\n        inputCols=[\"CallType\", \"CallDayOfWeek\"],\n        outputCols=[\"CallTypeIndex\", \"CallDayOfWeekIndex\"],\n        handleInvalid='skip'\n    )\n    encoder = OneHotEncoder(\n        inputCols=[\"CallTypeIndex\", \"CallDayOfWeekIndex\"],\n        outputCols=[\"CallTypeOhe\", \"CallDayOfWeekOhe\"]\n    )\n    assembler = VectorAssembler(\n        inputCols=[\"CallTypeOhe\", \"Priority\", \"CallDayOfWeekOhe\", \"DeltaPriority\"],\n        outputCol=\"features\"\n    )\n    regressor = LinearRegression(featuresCol=\"features\", labelCol=\"Delay\")\n    return Pipeline(\n        stages=[indexer, encoder, assembler, regressor]\n    )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5217b7d0-c10c-4eef-a336-b307ac6cfce7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(\"evaluate part 2\")\n\npipeline = define_pipeline()\n\nstages = pipeline.getStages()\nprint(\"4 elements in pipeline?\")\nprint(\n    len(stages) == 4\n)\nprint('is stage 0 a StringIndexer?')\nprint(isinstance(stages[0], StringIndexer))\n\nprint('is stage 1 a OneHotEncoder')\nprint(isinstance(stages[1], OneHotEncoder))\n\nprint('is stage 2 a VectorAssembler?')\nprint(isinstance(stages[2], VectorAssembler))\n\nprint('is stage 3 a LinearRegression?')\nprint(isinstance(stages[3], LinearRegression))\n\nprint('fits without errors?')\nmodel = pipeline.fit(df.limit(1000))\nprint(True)\n\nprediction = model.transform(df.where(df.CallNumber == 20110217)).collect()[0]\nprint('is DeltaPriority 1?')\nprint(prediction['DeltaPriority'] == 1 or prediction['DeltaPriority'] == '1')\nprint('has CallTypeOhe')\nprint('CallTypeOhe' in prediction)\n\nprint('has CallDayOfWeekOhe')\nprint('CallDayOfWeekOhe' in prediction)\n\nprint('has features')\nprint('features' in prediction)\n\nprint('has prediction')\nprint('prediction' in prediction)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5e6cd4d-8e4c-4c60-a6ce-73a120142668","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"evaluate part 2\n4 elements in pipeline?\nTrue\nis stage 0 a StringIndexer?\nTrue\nis stage 1 a OneHotEncoder\nTrue\nis stage 2 a VectorAssembler?\nTrue\nis stage 3 a LinearRegression?\nTrue\nfits without errors?\nTrue\nis DeltaPriority 1?\nTrue\nhas CallTypeOhe\nTrue\nhas CallDayOfWeekOhe\nTrue\nhas features\nTrue\nhas predictions\nFalse\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["evaluate part 2\n4 elements in pipeline?\nTrue\nis stage 0 a StringIndexer?\nTrue\nis stage 1 a OneHotEncoder\nTrue\nis stage 2 a VectorAssembler?\nTrue\nis stage 3 a LinearRegression?\nTrue\nfits without errors?\nTrue\nis DeltaPriority 1?\nTrue\nhas CallTypeOhe\nTrue\nhas CallDayOfWeekOhe\nTrue\nhas features\nTrue\nhas predictions\nFalse\n"]}}],"execution_count":0},{"cell_type":"code","source":["display(predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"99bf8f65-87d5-4421-bab0-ba6972636855","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[20110217,"Medical Incident",1,6,1,2.9333334,0.0,0.0,{"vectorType":"sparse","length":10,"indices":[0],"values":[1.0]},{"vectorType":"sparse","length":1,"indices":[0],"values":[1.0]},{"vectorType":"sparse","length":13,"indices":[0,10,11,12],"values":[1.0,1.0,1.0,1.0]},6.5364531837891136]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"CallNumber","type":"\"integer\"","metadata":"{}"},{"name":"CallType","type":"\"string\"","metadata":"{}"},{"name":"Priority","type":"\"integer\"","metadata":"{}"},{"name":"CallDayOfWeek","type":"\"integer\"","metadata":"{}"},{"name":"DeltaPriority","type":"\"integer\"","metadata":"{}"},{"name":"Delay","type":"\"float\"","metadata":"{}"},{"name":"CallTypeIndex","type":"\"double\"","metadata":"{\"ml_attr\":{\"vals\":[\"Medical Incident\",\"Structure Fire\",\"Alarms\",\"Outside Fire\",\"Other\",\"Odor (Strange / Unknown)\",\"Vehicle Fire\",\"Citizen Assist / Service Call\",\"Smoke Investigation (Outside)\",\"Electrical Hazard\",\"Fuel Spill\"],\"type\":\"nominal\",\"name\":\"CallTypeIndex\"}}"},{"name":"CallDayOfWeekIndex","type":"\"double\"","metadata":"{\"ml_attr\":{\"vals\":[\"6\",\"7\"],\"type\":\"nominal\",\"name\":\"CallDayOfWeekIndex\"}}"},{"name":"CallTypeOhe","type":"{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}","metadata":"{\"ml_attr\":{\"attrs\":{\"binary\":[{\"idx\":0,\"name\":\"Medical Incident\"},{\"idx\":1,\"name\":\"Structure Fire\"},{\"idx\":2,\"name\":\"Alarms\"},{\"idx\":3,\"name\":\"Outside Fire\"},{\"idx\":4,\"name\":\"Other\"},{\"idx\":5,\"name\":\"Odor (Strange / Unknown)\"},{\"idx\":6,\"name\":\"Vehicle Fire\"},{\"idx\":7,\"name\":\"Citizen Assist / Service Call\"},{\"idx\":8,\"name\":\"Smoke Investigation (Outside)\"},{\"idx\":9,\"name\":\"Electrical Hazard\"}]},\"num_attrs\":10}}"},{"name":"CallDayOfWeekOhe","type":"{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}","metadata":"{\"ml_attr\":{\"attrs\":{\"binary\":[{\"idx\":0,\"name\":\"6\"}]},\"num_attrs\":1}}"},{"name":"features","type":"{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}","metadata":"{\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":10,\"name\":\"Priority\"},{\"idx\":12,\"name\":\"DeltaPriority\"}],\"binary\":[{\"idx\":0,\"name\":\"CallTypeOhe_Medical Incident\"},{\"idx\":1,\"name\":\"CallTypeOhe_Structure Fire\"},{\"idx\":2,\"name\":\"CallTypeOhe_Alarms\"},{\"idx\":3,\"name\":\"CallTypeOhe_Outside Fire\"},{\"idx\":4,\"name\":\"CallTypeOhe_Other\"},{\"idx\":5,\"name\":\"CallTypeOhe_Odor (Strange / Unknown)\"},{\"idx\":6,\"name\":\"CallTypeOhe_Vehicle Fire\"},{\"idx\":7,\"name\":\"CallTypeOhe_Citizen Assist / Service Call\"},{\"idx\":8,\"name\":\"CallTypeOhe_Smoke Investigation (Outside)\"},{\"idx\":9,\"name\":\"CallTypeOhe_Electrical Hazard\"},{\"idx\":11,\"name\":\"CallDayOfWeekOhe_6\"}]},\"num_attrs\":13}}"},{"name":"prediction","type":"\"double\"","metadata":"{\"ml_attr\":{}}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CallNumber</th><th>CallType</th><th>Priority</th><th>CallDayOfWeek</th><th>DeltaPriority</th><th>Delay</th><th>CallTypeIndex</th><th>CallDayOfWeekIndex</th><th>CallTypeOhe</th><th>CallDayOfWeekOhe</th><th>features</th><th>prediction</th></tr></thead><tbody><tr><td>20110217</td><td>Medical Incident</td><td>1</td><td>6</td><td>1</td><td>2.9333334</td><td>0.0</td><td>0.0</td><td>Map(vectorType -> sparse, length -> 10, indices -> List(0), values -> List(1.0))</td><td>Map(vectorType -> sparse, length -> 1, indices -> List(0), values -> List(1.0))</td><td>Map(vectorType -> sparse, length -> 13, indices -> List(0, 10, 11, 12), values -> List(1.0, 1.0, 1.0, 1.0))</td><td>6.5364531837891136</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pipeline.getStages()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5131ee0-48b4-4797-952a-ec12a8f4d14a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: [StringIndexer_3f0c23a9ec5a,\n OneHotEncoder_7a97049b22e6,\n VectorAssembler_124b97c67555,\n LinearRegression_a3929d8c6911]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: [StringIndexer_3f0c23a9ec5a,\n OneHotEncoder_7a97049b22e6,\n VectorAssembler_124b97c67555,\n LinearRegression_a3929d8c6911]"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import DataFrame\n\ndef fit_model(df: DataFrame, pipeline: Pipeline) -> DataFrame:\n    train, test = df.randomSplit([.8, .2], seed=42)\n    model = pipeline.fit(train)\n    predictions = model.transform(test)\n    return predictions\\\n            .withColumnRenamed('Delay', 'DelayLabel')\\\n            .withColumnRenamed('prediction', 'DelayPrediction')\\\n            .select('DelayLabel', 'DelayPrediction')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"76ec8934-0f4a-4497-8cc7-718e6c905a06","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["predictions = fit_model(df, pipeline)\ndisplay(fit_model(df, pipeline))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f76d7df2-0968-4e88-8b95-8a9d7d2b0d9b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\ndef evaluate_r2(predictions_df: DataFrame) -> float:\n    evaluator = RegressionEvaluator(\n        predictionCol=\"DelayPrediction\",\n        labelCol=\"DelayLabel\",\n        metricName=\"r2\"\n    )\n\n    return evaluator.evaluate(predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5753ee43-aedf-49a0-ba5c-de59ead23875","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(\n        \"R2 \", evaluate_r2(predictions)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ca5bc930-929c-4689-a8f4-b4a891a95196","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"R2  0.005794662725845279\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["R2  0.005794662725845279\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"221108_evaluation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":35732860650641}},"nbformat":4,"nbformat_minor":0}
