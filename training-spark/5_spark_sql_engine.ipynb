{"cells":[{"cell_type":"markdown","source":["# Spark SQL Engine\n\n[ Ref _Learning Spark v2_ book, _Chapter 3_.]\n\nAt a programmatic level, Spark SQL allows developers to issue ANSI SQL:2003 compatible queries on structured data with a schema.\n\nThe diagram below summarizes the structure of Spark SQL and its usage:\n\n<img src=\"https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/assets/lesp_0401.png\" width=\"700\">\n\nRef: [O'Reilly](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ch04.html)\n\nSpark SQL allows to read data from structured file formats like the ones at the bottom of the stack (JSON, csv, etc). It then allows to access such data via ODBC connectors or SQL Spark shells by storing this data to temporarily table.\n\nHow can I actually run SQL commands in my notebook? We can define a `DataFrame` and run the `createOrReplaceTempView` method. It allows to run SQL queries programmatically and returns the result again as a `DataFrame`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6108315-d146-4838-8776-eca93ab011ba"}}},{"cell_type":"code","source":["sf_fire_file = \"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\"\ndf = spark.read.csv(sf_fire_file, header=True)\n\ndf.createOrReplaceTempView(\"firecalls\")\n\nsql_result_df = spark.sql(\"\"\"\n    SELECT CallType, count(*) as count\n    FROM firecalls\n    GROUP BY CallType\n    ORDER BY count(*) desc\n\"\"\")\ndisplay(sql_result_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af71b4e6-aeed-4128-babb-a3cc09ee4fef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Medical Incident",2843475],["Structure Fire",578998],["Alarms",483518],["Traffic Collision",175507],["Citizen Assist / Service Call",65360],["Other",56961],["Outside Fire",51603],["Vehicle Fire",20939],["Water Rescue",20037],["Gas Leak (Natural and LP Gases)",17284],["Electrical Hazard",12608],["Elevator / Escalator Rescue",11851],["Odor (Strange / Unknown)",11680],["Smoke Investigation (Outside)",9796],["Fuel Spill",5198],["HazMat",3437],["Industrial Accidents",2401],["Explosion",2307],["Aircraft Emergency",1196],["Train / Rail Incident",1116],["Assist Police",1058],["High Angle Rescue",1051],["Watercraft in Distress",728],["Extrication / Entrapped (Machinery, Vehicle)",628],["Oil Spill",441],["Confined Space / Structure Collapse",438],["Marine Fire",331],["Mutual Aid / Assist Outside Agency",298],["Suspicious Package",266],["Administrative",120],["Train / Rail Fire",23],["Lightning Strike (Investigation)",6]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"CallType","type":"\"string\"","metadata":"{}"},{"name":"count","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CallType</th><th>count</th></tr></thead><tbody><tr><td>Medical Incident</td><td>2843475</td></tr><tr><td>Structure Fire</td><td>578998</td></tr><tr><td>Alarms</td><td>483518</td></tr><tr><td>Traffic Collision</td><td>175507</td></tr><tr><td>Citizen Assist / Service Call</td><td>65360</td></tr><tr><td>Other</td><td>56961</td></tr><tr><td>Outside Fire</td><td>51603</td></tr><tr><td>Vehicle Fire</td><td>20939</td></tr><tr><td>Water Rescue</td><td>20037</td></tr><tr><td>Gas Leak (Natural and LP Gases)</td><td>17284</td></tr><tr><td>Electrical Hazard</td><td>12608</td></tr><tr><td>Elevator / Escalator Rescue</td><td>11851</td></tr><tr><td>Odor (Strange / Unknown)</td><td>11680</td></tr><tr><td>Smoke Investigation (Outside)</td><td>9796</td></tr><tr><td>Fuel Spill</td><td>5198</td></tr><tr><td>HazMat</td><td>3437</td></tr><tr><td>Industrial Accidents</td><td>2401</td></tr><tr><td>Explosion</td><td>2307</td></tr><tr><td>Aircraft Emergency</td><td>1196</td></tr><tr><td>Train / Rail Incident</td><td>1116</td></tr><tr><td>Assist Police</td><td>1058</td></tr><tr><td>High Angle Rescue</td><td>1051</td></tr><tr><td>Watercraft in Distress</td><td>728</td></tr><tr><td>Extrication / Entrapped (Machinery, Vehicle)</td><td>628</td></tr><tr><td>Oil Spill</td><td>441</td></tr><tr><td>Confined Space / Structure Collapse</td><td>438</td></tr><tr><td>Marine Fire</td><td>331</td></tr><tr><td>Mutual Aid / Assist Outside Agency</td><td>298</td></tr><tr><td>Suspicious Package</td><td>266</td></tr><tr><td>Administrative</td><td>120</td></tr><tr><td>Train / Rail Fire</td><td>23</td></tr><tr><td>Lightning Strike (Investigation)</td><td>6</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["In Databricks, you can convert a cell to a SQL cell by starting it with a `%sql`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7694cd6-51d7-4049-967e-4e57204fed54"}}},{"cell_type":"code","source":["%sql\nSELECT CallType, count(*) as count\nFROM firecalls\nGROUP BY CallType\nORDER BY count(*) desc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a53615eb-a59d-47b8-a75f-d6f0f82c5695"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Medical Incident",2843475],["Structure Fire",578998],["Alarms",483518],["Traffic Collision",175507],["Citizen Assist / Service Call",65360],["Other",56961],["Outside Fire",51603],["Vehicle Fire",20939],["Water Rescue",20037],["Gas Leak (Natural and LP Gases)",17284],["Electrical Hazard",12608],["Elevator / Escalator Rescue",11851],["Odor (Strange / Unknown)",11680],["Smoke Investigation (Outside)",9796],["Fuel Spill",5198],["HazMat",3437],["Industrial Accidents",2401],["Explosion",2307],["Aircraft Emergency",1196],["Train / Rail Incident",1116],["Assist Police",1058],["High Angle Rescue",1051],["Watercraft in Distress",728],["Extrication / Entrapped (Machinery, Vehicle)",628],["Oil Spill",441],["Confined Space / Structure Collapse",438],["Marine Fire",331],["Mutual Aid / Assist Outside Agency",298],["Suspicious Package",266],["Administrative",120],["Train / Rail Fire",23],["Lightning Strike (Investigation)",6]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"CallType","type":"\"string\"","metadata":"{}"},{"name":"count","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CallType</th><th>count</th></tr></thead><tbody><tr><td>Medical Incident</td><td>2843475</td></tr><tr><td>Structure Fire</td><td>578998</td></tr><tr><td>Alarms</td><td>483518</td></tr><tr><td>Traffic Collision</td><td>175507</td></tr><tr><td>Citizen Assist / Service Call</td><td>65360</td></tr><tr><td>Other</td><td>56961</td></tr><tr><td>Outside Fire</td><td>51603</td></tr><tr><td>Vehicle Fire</td><td>20939</td></tr><tr><td>Water Rescue</td><td>20037</td></tr><tr><td>Gas Leak (Natural and LP Gases)</td><td>17284</td></tr><tr><td>Electrical Hazard</td><td>12608</td></tr><tr><td>Elevator / Escalator Rescue</td><td>11851</td></tr><tr><td>Odor (Strange / Unknown)</td><td>11680</td></tr><tr><td>Smoke Investigation (Outside)</td><td>9796</td></tr><tr><td>Fuel Spill</td><td>5198</td></tr><tr><td>HazMat</td><td>3437</td></tr><tr><td>Industrial Accidents</td><td>2401</td></tr><tr><td>Explosion</td><td>2307</td></tr><tr><td>Aircraft Emergency</td><td>1196</td></tr><tr><td>Train / Rail Incident</td><td>1116</td></tr><tr><td>Assist Police</td><td>1058</td></tr><tr><td>High Angle Rescue</td><td>1051</td></tr><tr><td>Watercraft in Distress</td><td>728</td></tr><tr><td>Extrication / Entrapped (Machinery, Vehicle)</td><td>628</td></tr><tr><td>Oil Spill</td><td>441</td></tr><tr><td>Confined Space / Structure Collapse</td><td>438</td></tr><tr><td>Marine Fire</td><td>331</td></tr><tr><td>Mutual Aid / Assist Outside Agency</td><td>298</td></tr><tr><td>Suspicious Package</td><td>266</td></tr><tr><td>Administrative</td><td>120</td></tr><tr><td>Train / Rail Fire</td><td>23</td></tr><tr><td>Lightning Strike (Investigation)</td><td>6</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Catalyst optimizer\n\nThe Catalyst optimizer sits at the core of the Spark SQL engine. It takes a query and converts it to an execution plan. The plan goes through four **transformational phases**:\n\n1. **analysis**. The Spark SQL engine begins by generating an abstract syntax tree (AST) for the SQL or DataFrame query. In this initial phase, any columns or table names will be resolved by consulting an internal **Catalog**, a programmatic interface to Spark SQL that holds a list of names of columns, data types, functions, tables, databases, etc.\n2. **logical optimization**. Applying a standardrule based optimization approach, the Catalyst optimizer will first construct a set of multiple plans and then, using its cost-based optimizer (CBO), assign costs to each plan.\n3. **physical planning**. Spark SQL generates an optimal physical plan for the selected logical plan, using physical operators that match those available in the Spark execution engine.\n4. **code generation**. Generating efficient Java bytecode to run on each machine.\n\nThe image below summarazies these phases.\n\n![Four phases of Spark plan](https://www.databricks.com/wp-content/uploads/2018/05/Catalyst-Optimizer-diagram.png)\n\nRef: [Databricks](https://www.databricks.com/glossary/catalyst-optimizer)\n\nCan we see the plan of our transformations? Yes, we can print it from any `DataFrame` via the `explain` method."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c857d15c-2fb2-4729-9017-87bb489d51bd"}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n\ncount_df = (\n    df.select(\"CallType\", \"Call Number\")\n    .groupBy(\"CallType\")\n    .count()\n    .orderBy(\"count\", ascending=False)\n)\ndisplay(count_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e61a4fd-644a-4102-85cb-9132e5e2adc1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Medical Incident",2843475],["Structure Fire",578998],["Alarms",483518],["Traffic Collision",175507],["Citizen Assist / Service Call",65360],["Other",56961],["Outside Fire",51603],["Vehicle Fire",20939],["Water Rescue",20037],["Gas Leak (Natural and LP Gases)",17284],["Electrical Hazard",12608],["Elevator / Escalator Rescue",11851],["Odor (Strange / Unknown)",11680],["Smoke Investigation (Outside)",9796],["Fuel Spill",5198],["HazMat",3437],["Industrial Accidents",2401],["Explosion",2307],["Aircraft Emergency",1196],["Train / Rail Incident",1116],["Assist Police",1058],["High Angle Rescue",1051],["Watercraft in Distress",728],["Extrication / Entrapped (Machinery, Vehicle)",628],["Oil Spill",441],["Confined Space / Structure Collapse",438],["Marine Fire",331],["Mutual Aid / Assist Outside Agency",298],["Suspicious Package",266],["Administrative",120],["Train / Rail Fire",23],["Lightning Strike (Investigation)",6]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"CallType","type":"\"string\"","metadata":"{}"},{"name":"count","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CallType</th><th>count</th></tr></thead><tbody><tr><td>Medical Incident</td><td>2843475</td></tr><tr><td>Structure Fire</td><td>578998</td></tr><tr><td>Alarms</td><td>483518</td></tr><tr><td>Traffic Collision</td><td>175507</td></tr><tr><td>Citizen Assist / Service Call</td><td>65360</td></tr><tr><td>Other</td><td>56961</td></tr><tr><td>Outside Fire</td><td>51603</td></tr><tr><td>Vehicle Fire</td><td>20939</td></tr><tr><td>Water Rescue</td><td>20037</td></tr><tr><td>Gas Leak (Natural and LP Gases)</td><td>17284</td></tr><tr><td>Electrical Hazard</td><td>12608</td></tr><tr><td>Elevator / Escalator Rescue</td><td>11851</td></tr><tr><td>Odor (Strange / Unknown)</td><td>11680</td></tr><tr><td>Smoke Investigation (Outside)</td><td>9796</td></tr><tr><td>Fuel Spill</td><td>5198</td></tr><tr><td>HazMat</td><td>3437</td></tr><tr><td>Industrial Accidents</td><td>2401</td></tr><tr><td>Explosion</td><td>2307</td></tr><tr><td>Aircraft Emergency</td><td>1196</td></tr><tr><td>Train / Rail Incident</td><td>1116</td></tr><tr><td>Assist Police</td><td>1058</td></tr><tr><td>High Angle Rescue</td><td>1051</td></tr><tr><td>Watercraft in Distress</td><td>728</td></tr><tr><td>Extrication / Entrapped (Machinery, Vehicle)</td><td>628</td></tr><tr><td>Oil Spill</td><td>441</td></tr><tr><td>Confined Space / Structure Collapse</td><td>438</td></tr><tr><td>Marine Fire</td><td>331</td></tr><tr><td>Mutual Aid / Assist Outside Agency</td><td>298</td></tr><tr><td>Suspicious Package</td><td>266</td></tr><tr><td>Administrative</td><td>120</td></tr><tr><td>Train / Rail Fire</td><td>23</td></tr><tr><td>Lightning Strike (Investigation)</td><td>6</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["count_df.explain(extended=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfa63c89-72be-4fbd-8202-3ce06eee2954"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"== Parsed Logical Plan ==\n'Sort ['count DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623, Call Number#620]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Analyzed Logical Plan ==\nCallType: string, count: bigint\nSort [count#682L DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623, Call Number#620]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Optimized Logical Plan ==\nSort [count#682L DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#682L DESC NULLS LAST], true, 0\n   +- Exchange rangepartitioning(count#682L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#514]\n      +- HashAggregate(keys=[CallType#623], functions=[finalmerge_count(merge count#688L) AS count(1)#681L], output=[CallType#623, count#682L])\n         +- Exchange hashpartitioning(CallType#623, 200), ENSURE_REQUIREMENTS, [id=#511]\n            +- HashAggregate(keys=[CallType#623], functions=[partial_count(1) AS count#688L], output=[CallType#623, count#688L])\n               +- FileScan csv [CallType#623] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<CallType:string>\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["== Parsed Logical Plan ==\n'Sort ['count DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623, Call Number#620]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Analyzed Logical Plan ==\nCallType: string, count: bigint\nSort [count#682L DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623, Call Number#620]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Optimized Logical Plan ==\nSort [count#682L DESC NULLS LAST], true\n+- Aggregate [CallType#623], [CallType#623, count(1) AS count#682L]\n   +- Project [CallType#623]\n      +- Relation [Call Number#620,Unit ID#621,Incident Number#622,CallType#623,Call Date#624,Watch Date#625,Call Final Disposition#626,Available DtTm#627,Address#628,City#629,Zipcode of Incident#630,Battalion#631,Station Area#632,Box#633,OrigPriority#634,Priority#635,Final Priority#636,ALS Unit#637,Call Type Group#638,NumAlarms#639,UnitType#640,Unit sequence in call dispatch#641,Fire Prevention District#642,Supervisor District#643,... 4 more fields] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#682L DESC NULLS LAST], true, 0\n   +- Exchange rangepartitioning(count#682L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#514]\n      +- HashAggregate(keys=[CallType#623], functions=[finalmerge_count(merge count#688L) AS count(1)#681L], output=[CallType#623, count#682L])\n         +- Exchange hashpartitioning(CallType#623, 200), ENSURE_REQUIREMENTS, [id=#511]\n            +- HashAggregate(keys=[CallType#623], functions=[partial_count(1) AS count#688L], output=[CallType#623, count#688L])\n               +- FileScan csv [CallType#623] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<CallType:string>\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["How do we read this? It should be read bottom-up. So, looking at the _Parsed Logical Plan_:\n\n1. Relation [ ... ] csv (reading the csv data source)\n2. Project `CallType` and `CallNumber` (`CallNumber` will disappear from _Optimized Logical Plan_!)\n3. Aggregate (aggregating by `CallType` and counting)\n\nIs the plan behind the PySpark transformations of `count_df` the same as the `SQL` transformation behind `sql_result_df`?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de451c88-f5a1-4460-889b-51807189e81c"}}},{"cell_type":"code","source":["sql_result_df.explain(extended=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"426483f8-d38e-4e32-b866-55dfecfc7bd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"== Parsed Logical Plan ==\n'Sort ['count(1) DESC NULLS LAST], true\n+- 'Aggregate ['CallType], ['CallType, 'count(1) AS count#1225]\n   +- 'UnresolvedRelation [firecalls], [], false\n\n== Analyzed Logical Plan ==\nCallType: string, count: bigint\nSort [count#1225L DESC NULLS LAST], true\n+- Aggregate [CallType#1172], [CallType#1172, count(1) AS count#1225L]\n   +- SubqueryAlias firecalls\n      +- View (`firecalls`, [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,Neighborhood#1193,Location#1194,RowID#1195,Delay#1196])\n         +- Relation [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,... 4 more fields] csv\n\n== Optimized Logical Plan ==\nSort [count#1225L DESC NULLS LAST], true\n+- Aggregate [CallType#1172], [CallType#1172, count(1) AS count#1225L]\n   +- Project [CallType#1172]\n      +- Relation [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,... 4 more fields] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#1225L DESC NULLS LAST], true, 0\n   +- Exchange rangepartitioning(count#1225L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#1021]\n      +- HashAggregate(keys=[CallType#1172], functions=[finalmerge_count(merge count#1233L) AS count(1)#1226L], output=[CallType#1172, count#1225L])\n         +- Exchange hashpartitioning(CallType#1172, 200), ENSURE_REQUIREMENTS, [id=#1018]\n            +- HashAggregate(keys=[CallType#1172], functions=[partial_count(1) AS count#1233L], output=[CallType#1172, count#1233L])\n               +- FileScan csv [CallType#1172] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<CallType:string>\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["== Parsed Logical Plan ==\n'Sort ['count(1) DESC NULLS LAST], true\n+- 'Aggregate ['CallType], ['CallType, 'count(1) AS count#1225]\n   +- 'UnresolvedRelation [firecalls], [], false\n\n== Analyzed Logical Plan ==\nCallType: string, count: bigint\nSort [count#1225L DESC NULLS LAST], true\n+- Aggregate [CallType#1172], [CallType#1172, count(1) AS count#1225L]\n   +- SubqueryAlias firecalls\n      +- View (`firecalls`, [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,Neighborhood#1193,Location#1194,RowID#1195,Delay#1196])\n         +- Relation [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,... 4 more fields] csv\n\n== Optimized Logical Plan ==\nSort [count#1225L DESC NULLS LAST], true\n+- Aggregate [CallType#1172], [CallType#1172, count(1) AS count#1225L]\n   +- Project [CallType#1172]\n      +- Relation [Call Number#1169,Unit ID#1170,Incident Number#1171,CallType#1172,Call Date#1173,Watch Date#1174,Call Final Disposition#1175,Available DtTm#1176,Address#1177,City#1178,Zipcode of Incident#1179,Battalion#1180,Station Area#1181,Box#1182,OrigPriority#1183,Priority#1184,Final Priority#1185,ALS Unit#1186,Call Type Group#1187,NumAlarms#1188,UnitType#1189,Unit sequence in call dispatch#1190,Fire Prevention District#1191,Supervisor District#1192,... 4 more fields] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#1225L DESC NULLS LAST], true, 0\n   +- Exchange rangepartitioning(count#1225L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#1021]\n      +- HashAggregate(keys=[CallType#1172], functions=[finalmerge_count(merge count#1233L) AS count(1)#1226L], output=[CallType#1172, count#1225L])\n         +- Exchange hashpartitioning(CallType#1172, 200), ENSURE_REQUIREMENTS, [id=#1018]\n            +- HashAggregate(keys=[CallType#1172], functions=[partial_count(1) AS count#1233L], output=[CallType#1172, count#1233L])\n               +- FileScan csv [CallType#1172] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<CallType:string>\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["The _Optimized Logical Plan_ look actually the same for the transformation in SQL and in PySpark! That is, regardless of the language you use, your computation undergoes the same journey and the resulting bytecode is likely the same."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9af41856-8571-4817-94fb-6540a8237101"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5_spark_sql_engine","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2108355294076294}},"nbformat":4,"nbformat_minor":0}
